#hbase.zookeeper.quorum=192.168.40.49,192.168.40.68,192.168.40.48,192.168.40.50,192.168.40.51,192.168.40.52,192.168.40.53,192.168.40.54,192.168.40.55
#49集群测试环境
#hbase.zookeeper.quorum=hadoop-1,hadoop-2,hadoop-3,hadoop-4,hadoop-5,hadoop-6,hadoop-7,hadoop-8,hadoop-9
#线上环境
hbase.zookeeper.quorum=hadoop-2,hadoop-3,hadoop-4,hadoop-5,hadoop-6,hadoop-7,hadoop-8,hadoop-9,hadoop-10
#,hadoop-10,hadoop-11,hadoop-12,hadoop-13,hadoop-14,hadoop-15,hadoop-16,hadoop-17,hadoop-18,hadoop-19,hadoop-20
hbase.zookeeper.property.clientPort=2181
spark.sql.warehouse.dir=F:/Github/IhaveApple/spark-warehouse
#输入数据，格式为 2018-04-21 00:00:00,2,19980090,38692,202,2018-04-20 23:59:52,100,1,45,37,1027,568
dataPath=G:\\\u6570\u636e\\\u6641\u4f1f\u5ef7\\data
tablename=wj_test
family=value
#生成五分钟粒度
size=5min

#hbase.master = 192.168.40.49:60000
#hbase.zookeeper.quorum = 192.168.40.49
#hbase.zookeeper.property.clientPort = 2181

hbase.pool.size=100
#writeBufferSize的单位是byte字节数1024*512 KB
hbase.read.buffer=524288